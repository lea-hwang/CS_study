# Q5. HTTP1과 HTTP2에 대해 설명해주세요.(HTTP 전반적인 흐름에 대한 질문)

1997년 HTTP/1.1 릴리스부터 최근까지 사용된 프로토콜

그러나 2015년에는 특히 모바일 플랫폼과 서버 집약적인 그래픽 및 비디오를 처리할 때 대기 시간을 줄이는 여러 방법을 제공하는 HTTP/2라는 새로운 버전이 사용되었습니다.

HTTP/2는 그 이후로 점점 대중화되어 전 세계 웹사이트의 약 1/3이 HTTP/2를 지원하는 것으로 추정됩니다.



- HTTP 과정

  ![img](https://blog.kakaocdn.net/dn/kRrZb/btqI1FrWezD/OW1W90e3HrPDSyQxERjvwK/img.png)

1. 서버에서 TCP 소켓을 만들고(S1), 소켓을 바인딩하고(S2), 소켓에 커넥션이 들어올 수 있도록 하고(S3), 소켓이 커넥션을 기다린다(S4).

2. 클라이언트에서 웹 브라우저에 [http://www.google.com](http://www.google.com/) 이라고 입력한다. 그러면 DNS 에서 [www.google.com ](http://www.google.com/)에 대한 IP를 얻게 되고 생략 되어있지만 80포트 번호를 얻는다(C1).

3. 클라이언트에 웹 브라우저는 임의의 port 번호로(보통 30000번 이상) 소켓을 만들고(C2), connect() 함수로 TCP 연결을 시도한다.

4. 서버는 클라이언트의 연결을 감지 한 후 새로운 커넥션을 생성한다(S5, C4).

5. 동시에 서버는 클라이언트로부터 요청 받을 준비를 한다. 즉, buffer를 read 할 수 있게 한다(S6).

6. 클라이언트는 명령을 수행할 HTTP 요청 메시지를 서버로 보낸다(C5). 즉, buffer를 write한다.

7. 동시에 서버로 부터 받을 응답을 기다린다(C6). 즉, buffer를 read 할 수 있게 한다.

8. 서버는 클라이언트로 부터 요청받은 HTTP 메시지를 처리한다(.

9. 처리 후 응답 HTTP 메시지를 보낸다(S8).

10. 클라이언트는 HTTP 응답을 처리한다(C7)

11. 클라이언트와 서버간 TCP 연결을 종료한다(C8, S9)



#### HTTP1

- 1989년 Timothy Berners-Lee가 **World Wide Web의 통신 표준**으로 개발한 HTTP는 **클라이언트 컴퓨터와 로컬 또는 원격 웹 서버 간에 정보를 교환하는 최상위 응용 프로그램 프로토콜**.
- 이 과정에서 클라이언트는 메서드 를 호출하여 **서버에 텍스트 기반 요청을 보냄** .
- 이에 대한 **응답으로 서버는 HTML 페이지와 같은 리소스를 클라이언트에 다시 보냄**.
- 요청 및 응답 교환을 인터넷 프로토콜 스택의 단일 응용 프로그램 계층 으로 생각할 수 있음.
- 이 계층은 전송 계층 (일반적으로 전송 제어 프로토콜 또는 TCP 사용)과 네트워킹 계층 (인터넷 프로토콜 또는 IP 사용 ) 위에 있음.



#### HTTP2

- HTTP/2는 압축, 다중화 및 우선 순위 지정과 같은 기술을 사용하여 웹 페이지 로드 대기 시간을 줄이기 위해 주로 Google에서 개발한 SPDY 프로토콜로 시작되었음.
- 기술적인 관점에서 HTTP/1.1과 HTTP/2를 구별하는 가장 중요한 기능 중 하나는 인터넷 프로토콜 스택의 응용 프로그램 계층의 일부로 생각할 수 있는 **바이너리 프레이밍 계층**.
- 프레임은 통신의 최소단위이며, 프레임을 인터리빙, 식별자기반 프레임 재조립
  - 인터리빙
    - 각 채널의 신호를 하나씩 순차적으로 추출하고는,  이들을 일렬로(차례대로) 직렬화시키며(끼워가며), 다중화하는 과정
- **모든 요청과 응답을 일반 텍스트 형식으로 유지하는 HTTP/1.1**과 달리 **HTTP/2는 바이너리 프레이밍 계층을 사용하여 모든 메시지를 바이너리 형식으로 캡슐화하는 동시에 동사, 메서드 및 헤더와 같은 HTTP 의미 체계를 유지**.
- **이진 프로토콜(바이너리 프레이밍)** 
  - **HTTP 메시지가 캡슐화되어 클라이언트와 서버 사이에 전송되는 방식을 규정**
  - 모든 HTTP/2 통신은 더 작은 메시지와 프레임으로 분할되며, 각각은 바이너리 형식으로 인코딩
  - 더 이상 읽을 수도 없고 수작업을 만들어낼 수 없음 -> 새로운 최적화 기술 구현 가능 
- **병렬 요청이 동일한 커넥션 상에서 다루어질 수 있는 다중화 프로토콜**
- **전송된 데이터의 분명한 중복과 그런 데이터로부터 유발된 불필요한 오버헤드를 제거, 연속된 요청 사이의 매우 유사한 내용으로 존재하는 헤더들을 압축**
- **서버 푸쉬라고 불리는 메커니즘에 의해, 서버로 하여금 사전에 클라이언트 캐시를 필요하게 될 데이터로 채워 넣도록 허용**

 웹 브라우저와 서버의 진화로 바로 효과를 볼 수 있어서 급속한 확산



- Server Push : 서버가 클라이언트(브라우저)로 데이터를 전송해 주는 통신 방식. HTTP2의 서버 푸시를 활용하면 자원(JS, CSS, Image 등)을 하나의 TCP connection으로 클라이언트에 전달할 수 있습니다. 네트워크 활용도를 높여주고 빠른 로딩을 가능하게 합니다.

  | 기존 HTTP 통신                           | Server Push                         |
  | ---------------------------------------- | ----------------------------------- |
  | 클라이언트에서 일정한 주기로 서버에 질의 | 서버에서 클라이언트로 데이터를 전송 |
  | 불필요한 서버 및 네트워크 부하 발생      | 서버 비용 및 네트워크 부하 감소     |
  | 단방향성 통신                            | 양방향성 통신                       |
  | 정적인 웹                                | 동적인 웹                           |

  웹 통신 환경에서 양방향 통신, 즉 Server Push를 구현하기 위해 지금까지는 우회적인 기법의 실시간 통신 방식인 COMET을 사용해왔고, HTML5의 등장으로 SSE(Server-Sent Events)와 진정한 양방향 통신이 가능한 WebSocket이 등장했다.

  - Server Push 통신 방식

    **1.Ajax Polling**

    - 일정 주기로 서버에 요청을 보내어 서버의 이벤트를 받는 방식.

    

    **2.Ajax Long-Polling**

    - 요청에 대한 응답을 바로 하지 않고 일정 시간 대기하다가 이벤트가 발생한 경우에 응답을 하고, 클라이언트는 바로 재요청을 보내는 방식
    - 데이터 업데이트가 빈번한 경우네는 Polling에 비해 성능상 이점이 크지 않음

    

    **3.Server-Sent Events(SSE)**

    - 브라우저에 Push만 가능
    - 접속 처리 같은 대부분의 저수준 처리가 자동을 됨
    - HTTP 프로토콜 사용
    - HTML과 JavaScript 만으로 구현 가능
    - IE 지원하지 않음

    

    **4.WebSocket**

    - 클라이언트와 서버 간 양방향 통신
    - 불필요한 요청/응답 헤더 데이터가 존재하지 않음
    - 별도의 프로토콜 사용 - HTTP 프로토콜로 handshake 후 WebSocket 프로토콜 사용

    

  - 서버 푸시와 서비스 워커

    서비스 워커와 서버 푸시가 함께하면 더 강력해진다.

    *서버는 클라이언트의 상태를 모른다.* 

    URL요청마다 이미 전달한 자원을 서버는 재전송할 수 있다. (클라이언트 즉 브라우저가 어떤 데이터를 캐시하고 있는지 모르니까) 이 경우 당연히 불필요한 네트워크 트래픽을 증가시키게 되고 서버 푸시를 사용하는 의미가 사라진다.

    그렇기 때문에 우리의 웹 어플리케이션은 서비스 워커를 통해 캐시된 자원은 리턴받아야 한다. 그리하여 서버에 중복된 요청을 보내지 않도록 한다. 사실 이 모든 작업은 브라우저가 수행하기 때문에 유저는 별다른 구현을 하지 않아도 된다. 서비스 워커만 잘 작성하면 된다.



- 요청 및 응답 다중화

  - **HTTP/1.x**에서 성능 개선을 위해 **클라이언트가 여러 병렬 요청을 수행하려는 경우**, **여러 TCP 연결 사용**
    - 연결 당 **한번에 하나의 응답**만 전달되도록 보장
    - HOL(Head-of-Line) 차단
    - 기본 TCP 연결의 비효율적인 사용 초래
  - HTTP/2의 새 바이너리 프레이밍 계층
    - 이러한 **제한을 없애고** **전체 요청 및 응답 다중화 지원**
  - HTTP 메시지를 독립된 프레임으로 세분화하고 이 프레임을 인터리빙한 다음, 다른 쪽에서 다시 조립

- 출처당 하나의 연결

  -  **HTTP/2에서는 동일한 연결을 재사용하여 각 TCP 연결을 더 효율적으로 사용할 수 있으며 또한 전반적인 프로토콜 오버헤드를 대폭 줄일 수 있음**

  

- HOL Blocking이란? 

  - 네트워크에서 같은 큐에 있는 패킷이 첫번째 패킷에 의해 지연될 때 발생하는 성능 저하 현상

  - HTTP에서의 HOL Blocking

    - `HTTP/1.1`의 요청-응답 쌍은 항상 순서를 유지하고 동기적으로 수행되어야 한다.

      구체적으로 1개의 TCP 커넥션 상에서 3개의 이미지 (`a.png`, `b.png`, `c.png`)를 받는 경우, HTTP 리퀘스트는 다음과 같이 된다.

      ```text
      |---a.png---|
                  |---b.png---|
                              |---c.png---|
      ```

      하나의 요청이 처리되고 응답을 받은 후에 다음 요청을 보낸다.

      이전의 요청이 처리되지 않았다면 그 다음 요청은 보낼 수 없다는 것이다.

      만약 `a.png`의 요청이 막혀버리게 되면 `b,c`가 아무리 빨리 처리될 수 있더라도 전체적으로 느려지게 된다.

      ```text
      |------------a.png------------|
                                    |-b.png-|
                                            |---c.png---|
      ```

      이것이 바로 `HTTP/1.1`의 HOL Blocking이다.

      `HTTP/1.1`의 `pipelining`이라는 사양은 (조건부로) 요청만 먼저 보내버리는 것으로, 이 문제를 회피하는 것처럼 보인다.

      그러나 응답을 보낸 순서대로 무조건 받아야 하므로 `a.png`가 막혔을 경우에 생각보다 큰 효과를 보기 어렵다.

    - HTTP/2의 경우

      `HTTP/2`의 경우 요청은 하나의 연결에서 병렬적으로 보내질 수 있다.

      즉, `a ~ c.png`가 모두 병렬적으로 요청되고, 응답된다는 것이다.

      따라서 `a.png`가 시간이 걸리는 처리에서도, `b,c.png`는 먼저 받아서 보여줄 수 있다는 것이다.

      ```text
      |------------a.png------------|
      |-b.png-|
      |---c.png---|
      ```

      따라서 `HTTP/1.1`에서의 HOL Blocking은 `HTTP/2`에서는 발생하지 않는다고 말할 수 있다.

      또한 `HTTP/2`는 접속의 `Flow Control` 과 중요한 자원의 우선순위를 부여하는 `Priority` 를 가지고 있기 때문에 세세한 제어가 가능하다.



- HTTP/2에서 multiplexing
  - multiplexing : browser가 하나의 connection 상에서 동시에 여러 개의 request를 보내는 기술
  - HTTP/1.1에서는 단순히 request를 순서대로 보내곤 했다. 기본적으로 synchoronous하게 작동한다.
  - 초반에는 서버와 클라이언트 사이의 거리가 좁았으니 문제가 없었을테지만, 인터넷이 대중화되며 다른 국가간의 서버 연결또한 잦아지게 되었다. HTTP/1.1에서 데이터 하나 전송하는데 걸리는 시간이 100ms라고 치면, 파일 10개만 받아도 1000ms가 걸린다.
  - 이 문제에 대한 해결책으로 HTTP/2에서는 multiplexing이라는 방식을 채택하였다. 동시에 여러 개의 컨텐츠를 받는 것은 동일하지만, queue와 같은 기술을 통해서 하나의 connection만으로 컨텐츠를 동시에 받을 수 있도록 하는 것이다.



- 애플리케이션 수준 API는 여전히 기존 HTTP 형식으로 메시지를 생성하지만 기본 계층은 이러한 메시지를 바이너리로 변환.
- HTTP/2 이전에 생성된 웹 응용 프로그램이 새 프로토콜과 상호 작용할 때 정상적으로 계속 작동.
- 메시지를 바이너리로 변환하면 HTTP/2가 HTTP/1.1에서 사용할 수 없는 데이터 전달에 대한 새로운 접근 방식을 시도할 수 있음.
- 이는 두 프로토콜 간의 실질적인 차이점의 근원이 되는 대조임.



HTTP/2가 탄생한 이유

SPDY나 HTTP/2는 왜 등장했을까? 기존 웹 사이트는 지금처럼 콘텐츠가 많지 않았음. 그러나 현재는 여러가지 콘텐츠가 전달되고 용량도 많아지고 있어 한번의 액세스로 대량의 리퀘스트를 던지는 것이 당연해짐. 이러한 배경에서 HTTP/1.1에서는 프로토콜 수준에서는 제약이 많아 한계를 맞이했다는 것이 탄생한 큰 이유. 



참고)

https://kay0426.tistory.com/64

https://medium.com/@devfallingstar/network-http-2%EC%97%90%EC%84%9C-multiplexing%EC%9D%B4%EB%9E%80-565a7b184c

https://sunjoong85.github.io/pwa,/http2/2018/04/16/Pogressive-Web-App-HTTP2%EC%99%80-Server-Push.html

https://gyoogle.dev/blog/computer-science/network/OSI%207%EA%B3%84%EC%B8%B5.html

https://os94.tistory.com/186

https://velog.io/@dnr6054/HOL-Blocking